{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T09:10:38.348399Z",
     "start_time": "2024-02-21T09:10:30.657222100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras import layers, Sequential, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import generator\n",
    "\n",
    "#config = tf.ConfigProto(device_count = {'DML': 0})\n",
    "# sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    gen = generator.Generator(path_s=\"data/initial kernels/Kernel_Carbon_Adsorption.npy\",\n",
    "                        path_d=\"data/initial kernels/Kernel_Carbon_Desorption.npy\",\n",
    "                        path_p_d=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                        path_p_s=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                        path_a=\"data/initial kernels/Size_Kernel_Carbon_Adsorption.npy\"\n",
    "                )\n",
    "    gen.generate_data_set()\n",
    "\n",
    "def show_dataset():\n",
    "        dataset = hkl.load('data/datasets/carbon3.hkl')\n",
    "        i = 8\n",
    "        plt.plot(dataset[i][\"isotherm\"], marker=\".\")\n",
    "        plt.plot(dataset[i][\"pore_distribution\"], marker=\".\")\n",
    "        plt.show()\n",
    "        print(len(dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T09:10:38.360399400Z",
     "start_time": "2024-02-21T09:10:38.349398500Z"
    }
   },
   "id": "abffaafe1740b3f0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss', marker=\".\")\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T09:10:38.384396800Z",
     "start_time": "2024-02-21T09:10:38.357399100Z"
    }
   },
   "id": "39b0eb65244966a7"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def load_dataset(path, type=0):\n",
    "    min_exp_pressure_i = 40\n",
    "    max_exp_pressure_i = 458\n",
    "    with open(path, 'rb') as f:\n",
    "            dataset = np.load(f)\n",
    "            isotherm_data = dataset[\"isotherm_data\"]\n",
    "            pore_distribution_data = dataset[\"pore_distribution_data\"]\n",
    "    x = np.empty((isotherm_data.shape[0], (-min_exp_pressure_i + max_exp_pressure_i)))\n",
    "    #y = np.empty(pore_distribution_data.shape)\n",
    "    y = np.empty(shape=(len(isotherm_data), 2))\n",
    "    for i in range(len(isotherm_data)):\n",
    "        isotherm = isotherm_data[i][min_exp_pressure_i:max_exp_pressure_i]\n",
    "        isotherm -= min(isotherm)\n",
    "        isotherm /= max(isotherm)\n",
    "        pore_distribution = pore_distribution_data[i] - min(pore_distribution_data[i])\n",
    "        pore_distribution /= max(pore_distribution)\n",
    "        x[i] = isotherm\n",
    "        #y[i] = pore_distribution\n",
    "        if type == 0:\n",
    "            y[i] = np.array([0, 1])\n",
    "        else:\n",
    "            y[i] = np.array([1, 0])\n",
    "    x, y = shuffle(x, y)\n",
    "    return x, y\n",
    "\n",
    "x1, y1 = load_dataset('data/datasets/Silica_classification.npz', 0) # silica\n",
    "x2, y2 = load_dataset('data/datasets/Carbon_classification.npz', 1) # carbon\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:10:15.758960800Z",
     "start_time": "2024-02-16T11:10:10.887960200Z"
    }
   },
   "id": "6b25232e87d8279"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:10:16.660104Z",
     "start_time": "2024-02-16T11:10:16.582106600Z"
    }
   },
   "id": "e4fad87bc946e8a4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "## DENSE NET\n",
    "# model = Sequential(\n",
    "#     [\n",
    "#         Input(shape=len(x_train[0], )),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(400, activation='relu'),\n",
    "#         layers.Dropout(0.2),\n",
    "#         layers.Dense(len(y_train[0]), activation='relu') #  activation=tf.math.abs\n",
    "#     ]\n",
    "# )\n",
    "### CONV NET \n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(len(x_train[0]),1)))\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:12:42.138593600Z",
     "start_time": "2024-02-16T11:12:42.078570800Z"
    }
   },
   "id": "55379ad62e32d82"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:12:42.780209600Z",
     "start_time": "2024-02-16T11:12:42.764212400Z"
    }
   },
   "id": "5f652a0070f88e09"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.5389\n",
      "Epoch 1: accuracy improved from -inf to 0.53892, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.7055 - accuracy: 0.5389 - val_loss: 0.6738 - val_accuracy: 0.5925\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.6075\n",
      "Epoch 2: accuracy improved from 0.53892 to 0.60753, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.6569 - accuracy: 0.6075 - val_loss: 0.6459 - val_accuracy: 0.6259\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.6435\n",
      "Epoch 3: accuracy improved from 0.60753 to 0.64354, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.6191 - accuracy: 0.6435 - val_loss: 0.6071 - val_accuracy: 0.6664\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.6908\n",
      "Epoch 4: accuracy improved from 0.64354 to 0.69080, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.5772 - accuracy: 0.6908 - val_loss: 0.5695 - val_accuracy: 0.7834\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7602\n",
      "Epoch 5: accuracy improved from 0.69080 to 0.76016, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.5265 - accuracy: 0.7602 - val_loss: 0.5175 - val_accuracy: 0.8023\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.7987\n",
      "Epoch 6: accuracy improved from 0.76016 to 0.79872, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.4783 - accuracy: 0.7987 - val_loss: 0.4677 - val_accuracy: 0.8386\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8011\n",
      "Epoch 7: accuracy improved from 0.79872 to 0.80110, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.4492 - accuracy: 0.8011 - val_loss: 0.4584 - val_accuracy: 0.8061\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8390\n",
      "Epoch 8: accuracy improved from 0.80110 to 0.83901, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.4023 - accuracy: 0.8390 - val_loss: 0.4084 - val_accuracy: 0.8776\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8731\n",
      "Epoch 9: accuracy improved from 0.83901 to 0.87307, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.3521 - accuracy: 0.8731 - val_loss: 0.3701 - val_accuracy: 0.8974\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.8957\n",
      "Epoch 10: accuracy improved from 0.87307 to 0.89573, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.3080 - accuracy: 0.8957 - val_loss: 0.3504 - val_accuracy: 0.8837\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9017\n",
      "Epoch 11: accuracy improved from 0.89573 to 0.90166, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 451ms/step - loss: 0.2809 - accuracy: 0.9017 - val_loss: 0.2822 - val_accuracy: 0.9576\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9371\n",
      "Epoch 12: accuracy improved from 0.90166 to 0.93707, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.2258 - accuracy: 0.9371 - val_loss: 0.2507 - val_accuracy: 0.9678\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9449\n",
      "Epoch 13: accuracy improved from 0.93707 to 0.94485, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.1980 - accuracy: 0.9449 - val_loss: 0.2120 - val_accuracy: 0.9770\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9516\n",
      "Epoch 14: accuracy improved from 0.94485 to 0.95158, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 5s 459ms/step - loss: 0.1738 - accuracy: 0.9516 - val_loss: 0.1897 - val_accuracy: 0.9756\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9515\n",
      "Epoch 15: accuracy did not improve from 0.95158\n",
      "10/10 [==============================] - 4s 452ms/step - loss: 0.1597 - accuracy: 0.9515 - val_loss: 0.1629 - val_accuracy: 0.9827\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9685\n",
      "Epoch 16: accuracy improved from 0.95158 to 0.96847, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.1260 - accuracy: 0.9685 - val_loss: 0.1467 - val_accuracy: 0.9810\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9701\n",
      "Epoch 17: accuracy improved from 0.96847 to 0.97010, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.1148 - accuracy: 0.9701 - val_loss: 0.1289 - val_accuracy: 0.9857\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9757\n",
      "Epoch 18: accuracy improved from 0.97010 to 0.97565, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0985 - accuracy: 0.9757 - val_loss: 0.1132 - val_accuracy: 0.9848\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9758\n",
      "Epoch 19: accuracy improved from 0.97565 to 0.97580, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.0899 - accuracy: 0.9758 - val_loss: 0.1152 - val_accuracy: 0.9850\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9181\n",
      "Epoch 20: accuracy did not improve from 0.97580\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.1942 - accuracy: 0.9181 - val_loss: 0.1867 - val_accuracy: 0.9509\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9548\n",
      "Epoch 21: accuracy did not improve from 0.97580\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.1284 - accuracy: 0.9548 - val_loss: 0.1610 - val_accuracy: 0.9624\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9510\n",
      "Epoch 22: accuracy did not improve from 0.97580\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.1350 - accuracy: 0.9510 - val_loss: 0.1846 - val_accuracy: 0.9475\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9628\n",
      "Epoch 23: accuracy did not improve from 0.97580\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.1098 - accuracy: 0.9628 - val_loss: 0.1020 - val_accuracy: 0.9842\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9785\n",
      "Epoch 24: accuracy improved from 0.97580 to 0.97846, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 0.0782 - accuracy: 0.9785 - val_loss: 0.0906 - val_accuracy: 0.9849\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9819\n",
      "Epoch 25: accuracy improved from 0.97846 to 0.98187, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.0672 - accuracy: 0.9819 - val_loss: 0.0817 - val_accuracy: 0.9884\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9835\n",
      "Epoch 26: accuracy improved from 0.98187 to 0.98354, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0644 - accuracy: 0.9835 - val_loss: 0.0771 - val_accuracy: 0.9873\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9838\n",
      "Epoch 27: accuracy improved from 0.98354 to 0.98382, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.0606 - accuracy: 0.9838 - val_loss: 0.0730 - val_accuracy: 0.9889\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9855\n",
      "Epoch 28: accuracy improved from 0.98382 to 0.98547, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0570 - accuracy: 0.9855 - val_loss: 0.0709 - val_accuracy: 0.9896\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9850\n",
      "Epoch 29: accuracy did not improve from 0.98547\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 0.0554 - accuracy: 0.9850 - val_loss: 0.0676 - val_accuracy: 0.9887\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9855\n",
      "Epoch 30: accuracy did not improve from 0.98547\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.0543 - accuracy: 0.9855 - val_loss: 0.0646 - val_accuracy: 0.9888\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9859\n",
      "Epoch 31: accuracy improved from 0.98547 to 0.98594, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0513 - accuracy: 0.9859 - val_loss: 0.0626 - val_accuracy: 0.9900\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9869\n",
      "Epoch 32: accuracy improved from 0.98594 to 0.98688, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 447ms/step - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9900\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9870\n",
      "Epoch 33: accuracy improved from 0.98688 to 0.98701, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0491 - accuracy: 0.9870 - val_loss: 0.0582 - val_accuracy: 0.9887\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9867\n",
      "Epoch 34: accuracy did not improve from 0.98701\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.0481 - accuracy: 0.9867 - val_loss: 0.0563 - val_accuracy: 0.9889\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9874\n",
      "Epoch 35: accuracy improved from 0.98701 to 0.98735, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 0.0558 - val_accuracy: 0.9901\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9874\n",
      "Epoch 36: accuracy improved from 0.98735 to 0.98740, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0451 - accuracy: 0.9874 - val_loss: 0.0533 - val_accuracy: 0.9889\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9882\n",
      "Epoch 37: accuracy improved from 0.98740 to 0.98817, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0441 - accuracy: 0.9882 - val_loss: 0.0511 - val_accuracy: 0.9906\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9883\n",
      "Epoch 38: accuracy improved from 0.98817 to 0.98830, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0425 - accuracy: 0.9883 - val_loss: 0.0490 - val_accuracy: 0.9906\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9886\n",
      "Epoch 39: accuracy improved from 0.98830 to 0.98858, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0417 - accuracy: 0.9886 - val_loss: 0.0478 - val_accuracy: 0.9908\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9881\n",
      "Epoch 40: accuracy did not improve from 0.98858\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0482 - val_accuracy: 0.9922\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9888\n",
      "Epoch 41: accuracy improved from 0.98858 to 0.98883, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 0.0460 - val_accuracy: 0.9921\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9892\n",
      "Epoch 42: accuracy improved from 0.98883 to 0.98915, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0462 - val_accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9895\n",
      "Epoch 43: accuracy improved from 0.98915 to 0.98952, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.0425 - val_accuracy: 0.9918\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9894\n",
      "Epoch 44: accuracy did not improve from 0.98952\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0421 - val_accuracy: 0.9954\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9900\n",
      "Epoch 45: accuracy improved from 0.98952 to 0.99001, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0363 - accuracy: 0.9900 - val_loss: 0.0411 - val_accuracy: 0.9954\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9911\n",
      "Epoch 46: accuracy improved from 0.99001 to 0.99113, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 0.0396 - val_accuracy: 0.9943\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9905\n",
      "Epoch 47: accuracy did not improve from 0.99113\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 0.0376 - val_accuracy: 0.9926\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9908\n",
      "Epoch 48: accuracy did not improve from 0.99113\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.0368 - val_accuracy: 0.9925\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9915\n",
      "Epoch 49: accuracy improved from 0.99113 to 0.99149, saving model to data/models\\classification.keras\n",
      "10/10 [==============================] - 4s 446ms/step - loss: 0.0318 - accuracy: 0.9915 - val_loss: 0.0379 - val_accuracy: 0.9941\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9911\n",
      "Epoch 50: accuracy did not improve from 0.99149\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0364 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath='data/models/classification.keras', save_best_only=True,\n",
    "#                                            monitor='val_loss', mode='min', verbose=1, save_weights_only=False,\n",
    "#                                            save_freq='epoch')\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath='data/models/classification.keras', save_best_only=True,\n",
    "                                           monitor='accuracy', mode='max', verbose=1, save_weights_only=False,\n",
    "                                           save_freq='epoch')\n",
    "\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                   patience=100, verbose=1, mode='auto')\n",
    "# from keras import backend as K\n",
    "# K.set_value(model.optimizer.learning_rate, 0.001)\n",
    "history = model.fit(np.array(x_train), np.array(y_train),\n",
    "                    epochs=50, batch_size=5000, shuffle=True,\n",
    "                    validation_data=(np.array(x_test), np.array(y_test)), callbacks=[mcp_save])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:16:25.253474300Z",
     "start_time": "2024-02-16T11:12:43.331583300Z"
    }
   },
   "id": "d25b994a185e43b5"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:18:55.391087300Z",
     "start_time": "2024-02-16T11:18:49.518452600Z"
    }
   },
   "id": "8b7e56670053b97b"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458/1458 [==============================] - 7s 5ms/step\n",
      "prediction shape: (46656, 2)\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model('data/models/classification.keras', custom_objects={'abs': tf.math.abs})\n",
    "#\n",
    "prediction = model.predict(np.array(x_train))\n",
    "print(\"prediction shape:\", prediction.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T11:21:25.580136300Z",
     "start_time": "2024-02-16T11:21:17.549348Z"
    }
   },
   "id": "4147cb982df89488"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "pore_widths = np.load(\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\")\n",
    "pressures = np.load(\"data/initial kernels/Pressure_Silica.npy\")\n",
    "NX, NY = 4 , 5\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        k = np.random.randint(0, len(x_train))\n",
    "        x_scale_factor = max(pore_widths)/len(x_train[k])\n",
    "        axis[i, j].plot(pore_widths/x_scale_factor, prediction[k], marker=\".\", label=f\"Prediction\") \n",
    "        axis[i, j].plot(pore_widths/x_scale_factor, y_train[k], marker=\".\", label=\"Real distribution\")\n",
    "        axis[i, j].plot(x_train[k], label=\"Isotherm\")\n",
    "        ###\n",
    "        ### Distribution and Isotherm \n",
    "        # axis[i, j].plot(pore_widths/x_scale_factor), y_train[k], marker=\".\", label=\"Distribution\")\n",
    "        # axis[i, j].plot(x_train[k], marker=\".\", label=\"Isotherm\")\n",
    "        ###\n",
    "        \n",
    "        axis[i, j].set_title(f\"â„– {k}\")\n",
    "        axis[i, j].title.set_size(10)\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T19:41:16.288346200Z",
     "start_time": "2024-02-15T19:40:52.808721900Z"
    }
   },
   "id": "8d8ef97cab3bdc29"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (128,) and (130,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m prediction2 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39marray([test]))\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m     15\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(pore_widths, prediction2, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpore_widths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpore_distribution\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreal\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n\u001B[0;32m     18\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\venv10\\lib\\site-packages\\matplotlib\\pyplot.py:3575\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3567\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   3568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\n\u001B[0;32m   3569\u001B[0m     \u001B[38;5;241m*\u001B[39margs: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m ArrayLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3573\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3574\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Line2D]:\n\u001B[1;32m-> 3575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   3576\u001B[0m         \u001B[38;5;241m*\u001B[39margs,\n\u001B[0;32m   3577\u001B[0m         scalex\u001B[38;5;241m=\u001B[39mscalex,\n\u001B[0;32m   3578\u001B[0m         scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   3579\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m   3580\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3581\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\venv10\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1479\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1480\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1718\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1719\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1720\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1721\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1722\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1723\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\venv10\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, axes, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    301\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    302\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 303\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\venv10\\lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001B[0m\n\u001B[0;32m    496\u001B[0m     axes\u001B[38;5;241m.\u001B[39myaxis\u001B[38;5;241m.\u001B[39mupdate_units(y)\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 499\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must have same first dimension, but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    500\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y can be no greater than 2D, but have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    503\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (128,) and (130,)"
     ]
    }
   ],
   "source": [
    "import generator\n",
    "gen = generator.Generator(path_s=\"data/initial kernels/Kernel_Carbon_Adsorption.npy\",\n",
    "                        path_d=\"data/initial kernels/Kernel_Carbon_Desorption.npy\",\n",
    "                        path_p_d=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                        path_p_s=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                        path_a=\"data/initial kernels/Size_Kernel_Carbon_Adsorption.npy\"\n",
    "                )\n",
    "gen.generate_pore_distribution(d0_1=5.41454887, d0_2=16.07756851, sigma1=4.19612833, sigma2=6.50303474, a=0.66)\n",
    "gen.calculate_calculate_isotherms_right()\n",
    "test = gen.n_s[min_exp_pressure_i:max_exp_pressure_i]\n",
    "test = test - min(test)\n",
    "test /= max(test)\n",
    "# plt.plot(test, marker=\".\")\n",
    "prediction2 = model.predict(np.array([test])).T\n",
    "plt.plot(pore_widths, prediction2, marker=\".\")\n",
    "plt.plot(pore_widths, gen.pore_distribution, marker=\".\", label=\"real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T19:40:50.233206300Z",
     "start_time": "2024-02-15T19:40:47.855160900Z"
    }
   },
   "id": "676bb46f5aba945f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen.pore_distribution = prediction[i]\n",
    "gen.calculate_calculate_isotherms_right()\n",
    "plt.plot(gen.pressures_s[min_exp_pressure_i:max_exp_pressure_i], x_train[i], marker=\".\", label=\"Real\")\n",
    "plt.plot(gen.pressures_s[min_exp_pressure_i:max_exp_pressure_i], gen.n_s[min_exp_pressure_i:max_exp_pressure_i], marker=\".\", label=\"Net\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-11T09:54:54.596885500Z"
    }
   },
   "id": "4a3872c3c5b2caf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('data/models/carbon_two_equal_peaks_conv.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-11T09:54:54.598898Z"
    }
   },
   "id": "511a0093e2bc5d71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-11T09:54:54.600885200Z"
    }
   },
   "id": "5f3cf2014e272e2c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
